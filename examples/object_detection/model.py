import torch.nn.functional as F
import torch
import torch.nn as nn
import os
import numpy as np


def parse_model_cfg(path):

    if not path.endswith(".cfg"):  # add .cfg suffix if omitted
        path += ".cfg"
    if not os.path.exists(path) and os.path.exists("cfg" + os.sep + path):
        path = "cfg" + os.sep + path

    with open(path, "r") as f:
        lines = f.read().split("\n")
    lines = [x for x in lines if x and not x.startswith("#")]
    lines = [x.rstrip().lstrip() for x in lines]  # get rid of fringe whitespaces
    mdefs = []  # module definitions
    for line in lines:
        if line.startswith("["):  # This marks the start of a new block
            mdefs.append({})
            mdefs[-1]["type"] = line[1:-1].rstrip()
            if mdefs[-1]["type"] == "convolutional":
                mdefs[-1][
                    "batch_normalize"
                ] = 0  # pre-populate with zeros (may be overwritten later)
        else:
            key, val = line.split("=")
            key = key.rstrip()

            if "anchors" in key:
                mdefs[-1][key] = np.array([float(x) for x in val.split(",")]).reshape(
                    (-1, 2)
                )  #
            else:
                mdefs[-1][key] = val.strip()

    # Check all fields are supported
    supported = [
        "type",
        "batch_normalize",
        "filters",
        "size",
        "stride",
        "pad",
        "activation",
        "layers",
        "groups",
        "from",
        "mask",
        "anchors",
        "classes",
        "num",
        "jitter",
        "ignore_thresh",
        "truth_thresh",
        "random",
        "stride_x",
        "stride_y",
    ]

    f = []  # fields
    for x in mdefs[1:]:
        [f.append(k) for k in x if k not in f]
    u = [x for x in f if x not in supported]  # unsupported fields

    assert not any(u), (
        "Unsupported fields %s in %s. See \
    https://github.com/ultralytics/yolov3/issues/631"
        % (u, path)
    )

    return mdefs


def create_modules(module_defs, img_size, arc):
    # Constructs module list of layer blocks from module configuration in module_defs

    hyperparams = module_defs.pop(0)
    output_filters = [int(hyperparams["channels"])]
    module_list = nn.ModuleList()
    routs = []  # list of layers which rout to deeper layers
    yolo_index = -1

    for i, mdef in enumerate(module_defs):
        modules = nn.Sequential()

        if mdef["type"] == "convolutional":
            bn = int(mdef["batch_normalize"])
            filters = int(mdef["filters"])
            size = int(mdef["size"])
            stride = (
                int(mdef["stride"])
                if "stride" in mdef
                else (int(mdef["stride_y"]), int(mdef["stride_x"]))
            )
            pad = (size - 1) // 2 if int(mdef["pad"]) else 0
            modules.add_module(
                "Conv2d",
                nn.Conv2d(
                    in_channels=output_filters[-1],
                    out_channels=filters,
                    kernel_size=size,
                    stride=stride,
                    padding=pad,
                    groups=int(mdef["groups"]) if "groups" in mdef else 1,
                    bias=not bn,
                ),
            )
            if bn:
                modules.add_module("BatchNorm2d", nn.BatchNorm2d(filters, momentum=0.1))
            if (
                mdef["activation"] == "leaky"
            ):  # TODO: activation study https://github.com/ultralytics/yolov3/issues/441
                modules.add_module("activation", nn.LeakyReLU(0.1, inplace=True))
                # modules.add_module('activation', nn.PReLU(num_parameters=1, init=0.10))
            elif mdef["activation"] == "swish":
                modules.add_module("activation", Swish())

        elif mdef["type"] == "maxpool":
            size = int(mdef["size"])
            stride = int(mdef["stride"])
            maxpool = nn.MaxPool2d(
                kernel_size=size, stride=stride, padding=int((size - 1) // 2)
            )
            if size == 2 and stride == 1:  # yolov3-tiny
                modules.add_module("ZeroPad2d", nn.ZeroPad2d((0, 1, 0, 1)))
                modules.add_module("MaxPool2d", maxpool)
            else:
                modules = maxpool

        elif mdef["type"] == "upsample":
            modules = nn.Upsample(scale_factor=int(mdef["stride"]), mode="nearest")

        elif mdef["type"] == "route":  # nn.Sequential() placeholder for 'route' layer
            layers = [int(x) for x in mdef["layers"].split(",")]
            filters = sum([output_filters[i + 1 if i > 0 else i] for i in layers])
            routs.extend([l if l > 0 else l + i for l in layers])
            # if mdef[i+1]['type'] == 'reorg3d':
            #     modules = nn.Upsample(scale_factor=1/float(mdef[i+1]['stride']), mode='nearest')  # reorg3d

        elif (
            mdef["type"] == "shortcut"
        ):  # nn.Sequential() placeholder for 'shortcut' layer
            filters = output_filters[int(mdef["from"])]
            layer = int(mdef["from"])
            routs.extend([i + layer if layer < 0 else layer])

        elif mdef["type"] == "reorg3d":  # yolov3-spp-pan-scale
            # torch.Size([16, 128, 104, 104])
            # torch.Size([16, 64, 208, 208]) <-- # stride 2 interpolate dimensions 2 and 3 to cat with prior layer
            pass

        elif mdef["type"] == "yolo":
            yolo_index += 1
            mask = [int(x) for x in mdef["mask"].split(",")]  # anchor mask
            modules = YOLOLayer(
                anchors=mdef["anchors"][mask],  # anchor list
                nc=int(mdef["classes"]),  # number of classes
                img_size=img_size,  # (416, 416)
                yolo_index=yolo_index,  # 0, 1 or 2
                arc=arc,
            )  # yolo architecture

        else:
            print("Warning: Unrecognized Layer Type: " + mdef["type"])

        # Register module list and number of output filters
        module_list.append(modules)
        output_filters.append(filters)

    return module_list, routs


class YOLOLayer(nn.Module):
    def __init__(self, anchors, nc, img_size, yolo_index, arc):
        super(YOLOLayer, self).__init__()

        self.anchors = torch.Tensor(anchors)
        self.na = len(anchors)  # number of anchors (3)
        self.nc = nc  # number of classes (80)
        self.no = nc + 5  # number of outputs
        self.nx = 0  # initialize number of x gridpoints
        self.ny = 0  # initialize number of y gridpoints
        self.arc = arc

    def create_grids(self, img_size=416, ng=(13, 13), device="cpu", type=torch.float32):
        nx, ny = ng  # x and y grid size
        self.img_size = max(img_size)
        self.stride = self.img_size / max(ng)

        # build xy offsets
        yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)])
        self.grid_xy = (
            torch.stack((xv, yv), 2).to(device).type(type).view((1, 1, ny, nx, 2))
        )

        # build wh gains
        self.anchor_vec = self.anchors.to(device) / self.stride
        self.anchor_wh = self.anchor_vec.view(1, self.na, 1, 1, 2).to(device).type(type)
        self.ng = torch.Tensor(ng).to(device)
        self.nx = nx
        self.ny = ny

    def forward(self, p, img_size, var=None):

        bs, _, ny, nx = p.shape  # bs, 255, 13, 13
        if (self.nx, self.ny) != (nx, ny):
            self.create_grids(img_size, (nx, ny), p.device, p.dtype)

        # p.view(bs, 255, 13, 13) -- > (bs, 3, 13, 13, 85)
        # (bs, anchors, grid, grid, classes + xywh)
        p = (
            p.view(bs, self.na, self.no, self.ny, self.nx)
            .permute(0, 1, 3, 4, 2)
            .contiguous()
        )  # prediction

        return p


class Darknet(nn.Module):
    # YOLOv3 object detection model

    def __init__(self, cfg, img_size=(416, 416), arc="default"):
        super(Darknet, self).__init__()

        self.module_defs = parse_model_cfg(cfg)
        self.module_list, self.routs = create_modules(self.module_defs, img_size, arc)
        self.yolo_layers = self.get_yolo_layers()

        # Darknet Header https://github.com/AlexeyAB/darknet/issues/2914#issuecomment-496675346
        self.version = np.array(
            [0, 2, 5], dtype=np.int32
        )  # (int32) version info: major, minor, revision
        self.seen = np.array(
            [0], dtype=np.int64
        )  # (int64) number of images seen during training

    def get_yolo_layers(self):
        return [i for i, x in enumerate(self.module_defs) if x["type"] == "yolo"]

    def forward(self, x):
        img_size = x.shape[-2:]
        layer_outputs = []
        output = []

        for i, (mdef, module) in enumerate(zip(self.module_defs, self.module_list)):
            mtype = mdef["type"]
            if mtype in ["convolutional", "upsample", "maxpool"]:
                x = module(x)
            elif mtype == "route":
                layers = [int(x) for x in mdef["layers"].split(",")]
                if len(layers) == 1:
                    x = layer_outputs[layers[0]]
                else:
                    try:
                        x = torch.cat([layer_outputs[i] for i in layers], 1)
                    except:  # apply stride 2 for darknet reorg layer
                        layer_outputs[layers[1]] = F.interpolate(
                            layer_outputs[layers[1]], scale_factor=[0.5, 0.5]
                        )
                        x = torch.cat([layer_outputs[i] for i in layers], 1)

            elif mtype == "shortcut":
                x = x + layer_outputs[int(mdef["from"])]
            elif mtype == "yolo":
                output.append(module(x, img_size))
            layer_outputs.append(x if i in self.routs else [])

        return output


if __name__ == "__main__":
    darknet = Darknet("yolov3.cfg")

    darknet.train()

    x = torch.rand(10, 3, 416, 416)
    y = darknet(x)

    for z in y:
        print(z.shape)
